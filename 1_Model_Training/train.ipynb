{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf24a4b",
   "metadata": {},
   "source": [
    "# install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69ed99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision wandb timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935cbc1c",
   "metadata": {},
   "source": [
    "# import and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8215d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "PROJECT_NAME = \"pet-breed-classifier\"\n",
    "NUM_CLASSES = 37\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5  # change if you want\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273ead5",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32826f6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class OxfordPetsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Oxford-IIIT Pet Dataset loader using trainval/test txt files.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split=\"trainval\", transform=None):\n",
    "        \"\"\"\n",
    "        root: path to dataset root containing 'images/' and 'annotations/'\n",
    "        split: 'trainval' or 'test'\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        annot_file = os.path.join(root, \"annotations\", f\"{split}.txt\")\n",
    "        self.samples = []\n",
    "\n",
    "        with open(annot_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                img_id = parts[0]           # e.g. 'Abyssinian_1'\n",
    "                class_id = int(parts[1])    # 1..37\n",
    "\n",
    "                img_path = os.path.join(root, \"images\", img_id + \".jpg\")\n",
    "                label = class_id - 1        # convert to 0..36\n",
    "                self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
